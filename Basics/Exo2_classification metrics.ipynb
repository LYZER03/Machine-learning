{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the classification metrics from scratch\n",
    "\n",
    "To this exercise you will need to implement the precision, recall, and f1-measure without using scikit-learn or any other library that already implements such metrics.\n",
    "\n",
    "Your algorithm should take as input the predictions made on the test set (y_pred) and the actual class values of such set (y_test).\n",
    "\n",
    "You will need to find at least the TP, FP, and FN to compute the three metrics.\n",
    "\n",
    "You can use this part of code to help your implementation or you can define your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.97\n",
      "Recall: 0.94\n",
      "F1-Score: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DONG\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the precision score\n",
    "    :param y_true: True labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: Precision score\n",
    "    \"\"\"\n",
    "    #Your code here\n",
    "\n",
    "    # \"true_positive\" is where both true labels and predicted labels are 1.\n",
    "    true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
    "\n",
    "    # \"false_positive\" is where both true labels are 0 and predicted labels are 1.\n",
    "    false_positive = np.sum((y_true == 0) & (y_pred == 1))\n",
    "\n",
    "    # Precision is the number of correctly predicted positives (True Positive) \n",
    "    # divided by all predicted positives (True Positive + False Positive).\n",
    "    # It measures the accuracy of the positive predictions.\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the recall score\n",
    "    :param y_true: True labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: Recall score\n",
    "    \"\"\"\n",
    "   #Your code here\n",
    "    # Count where both true labels and predicted labels are 1\n",
    "    true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
    "\n",
    "    # Count where true labels are 1 (positive class) but predicted labels are 0\n",
    "    false_negative = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # The recall shows the percentage of positive results predicted by our model.\n",
    "    # Recall is similar to Precision\n",
    "    # He is the number of correctly predicted positives (True Positive) divided by all positives (True Positive + False Negative).\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the F1 score\n",
    "    :param y_true: True labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: F1 score\n",
    "    \"\"\"\n",
    "   #Your code here\n",
    "    # While useful, neither precision nor recall can fully evaluate a Machine Learning model.\n",
    "    # Those metrics indicating that our model is efficient, when in fact it's naÃ¯ve. \n",
    "    # In other words, the high score presented will not indicate real performance.\n",
    "\n",
    "    # Fortunately for us, The F1 Score provides a relatively accurate assessment of our model's performance.\n",
    "\n",
    "    precision_val = precision(y_true, y_pred)\n",
    "    recall_val = recall(y_true, y_pred)\n",
    "\n",
    "    # F1-score is calculated as the harmonic mean of precision and recall. \n",
    "    # It provides a balance between precision and recall, \n",
    "    # making it a useful metric when there is an imbalance between the classes.\n",
    "    f1 = 2 * (precision_val * recall_val) / (precision_val + recall_val) if (precision_val + recall_val) > 0 else 0\n",
    "    return f1\n",
    "\n",
    "# Fit a model and make predictions\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall and F1-score\n",
    "p = precision(y_test, y_pred)\n",
    "r = recall(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision: {:.2f}\".format(p))\n",
    "print(\"Recall: {:.2f}\".format(r))\n",
    "print(\"F1-Score: {:.2f}\".format(f1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "914a73f32d308ae8debcaf6a2c2af8e68613f922620f6864a793ea7cdc2482ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
