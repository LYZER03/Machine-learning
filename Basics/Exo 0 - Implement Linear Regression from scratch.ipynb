{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Implementing Linear Regression from Scratch with California Housing Dataset </b>\n",
    "\n",
    "Objective:\n",
    "This exercise aims to provide a hands-on experience in implementing linear regression from scratch using the California housing dataset. You will gain a deeper understanding of the inner workings of linear regression, including the concepts of cost function, and gradient descent optimization.\n",
    "\n",
    "<b>Steps:</b>\n",
    "\n",
    "1- Load the California Housing Dataset:\n",
    "\n",
    "- Use the fetch_california_housing function from scikit-learn to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "data, target = housing.data, housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore the data\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Data Preprocessing:\n",
    "\n",
    "- Add a bias term to the input features.\n",
    "- Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a bias term to the input features\n",
    "data_bias = np.c_[np.ones((data.shape[0], 1)), data]\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_bias, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Standardization:\n",
    "\n",
    "- Standardize the input features using StandardScaler from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Linear Regression Implementation:\n",
    "\n",
    "- Implement a simple linear regression class with methods for fitting the model and making predictions.\n",
    "- Use mean squared error as the cost function.\n",
    "- Utilize gradient descent for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression implementation from scratch\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        #init our variables\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.w = None # the weight\n",
    "        self.b = None # the bias\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.w = np.zeros(num_features) # init the weights to zero with the same shape as matrix X\n",
    "        self.b = 0 # Bias is a single value init to zero\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Actuel prediction with current weights\n",
    "            y_pred = np.dot(X, self.w) + self.b\n",
    "\n",
    "            # Compute the gradiant descent with derivative equation of w and b\n",
    "            dw = (1/num_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/num_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # Update the w and b with gradient descent it should decrease w and b towards minimum value\n",
    "            self.w -= self.learning_rate * dw\n",
    "            self.b -= self.learning_rate * db\n",
    "\n",
    "        return self\n",
    "\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict y values\n",
    "        return np.dot(X, self.w) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Training the Model:\n",
    "\n",
    "- Instantiate the linear regression model.\n",
    "- Train the model on the training set using the implemented gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x16e170ec3d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train the model\n",
    "model = LinearRegression(learning_rate=1, n_iterations=1000)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Prediction and Evaluation:\n",
    "\n",
    "- Make predictions on the test set.\n",
    "- Evaluate the model's performance using mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803163672.2826726\n",
      "428836664.45644003\n",
      "Mean Squared Error on Test Set: 8.580387824473165e+18\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = np.mean((predictions - y_test)**2)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Mean Squared Error (MSE) of 8 indicates that, on average, the squares of the differences between model predictions and actual values on the test set are equal to 8. The lower the MSE, the better the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
